1. Look up the specs for the totient nodes. Having read the Roofline paper,
   draw a roofline diagram for one totient node (assuming only the
   host cores are used, for the moment).  How do things change with
   the addition of the two Phi boards?
R:
The totient nodes are Intel Xeon E5-2520 v3 processors with 32 GB RAM per node.
The bandwidth is 59 GB/sec and the peak flop rate is 120 GF/sec (preclass questions 2015-08-27)

2. What is the difference between two cores and one core with
   hyperthreading?
R: Hyperthreading has two virtual cores, and two cores has actually two
physical cores.

3. Do a Google search to find a picture of how memories are arranged
   on the Phi architecture.  Describe the setup briefly in your own
   words.  Is the memory access uniform or non-uniform?
R:https://software.intel.com/en-us/articles/intel-xeon-phi-coprocessor-codename-knights-corner

The memory addreses are uniformly distributed among a ring. The memory access is uniform

4. Consider the parallel dot product implementations suggested in the
   slides.  As a function of the number of processors, the size of the
   vectors, and typical time to send a message, can you predict the
   speedup associated with parallelizing a dot product computation?
   [Note that dot products have low arithmetic intensity -- the
    roofline model may be useful for reasoning about the peak
    performance for computing pieces of the dot product]
R:Define, s:time to send a message, p:number of processors, n: size of the vectors.
Let t be the time of doing an elemental operation, then the serial time is 2*N*t. 
So the speed up is

2*N*t/((N*t/p)+s*p+N*t)
